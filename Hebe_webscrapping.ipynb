{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Web scrapping"
      ],
      "metadata": {
        "id": "b-aEn_OhlfvL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGzzOFYWgwKF",
        "outputId": "7977e347-da0f-4d25-e5ba-7baa37e048fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting playwright\n",
            "  Downloading playwright-1.33.0-py3-none-manylinux1_x86_64.whl (35.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.3/35.3 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting greenlet==2.0.1 (from playwright)\n",
            "  Downloading greenlet-2.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (539 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m539.9/539.9 kB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyee==9.0.4 (from playwright)\n",
            "  Downloading pyee-9.0.4-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pyee==9.0.4->playwright) (4.5.0)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3108, in _dep_map\n",
            "    return self.__dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2901, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _DistInfoDistribution__dep_map\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 242, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 441, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 572, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/metadata/pkg_resources.py\", line 216, in iter_dependencies\n",
            "    return self._dist.requires(extras)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2821, in requires\n",
            "    dm = self._dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3110, in _dep_map\n",
            "    self.__dep_map = self._compute_dependencies()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3120, in _compute_dependencies\n",
            "    reqs.extend(parse_requirements(req))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3177, in __init__\n",
            "    self.specs = [(spec.operator, spec.version) for spec in self.specifier]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/specifiers.py\", line 694, in __iter__\n",
            "    def __iter__(self) -> Iterator[_IndividualSpecifier]:\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 207, in exc_logging_wrapper\n",
            "    logger.debug(\"Exception information:\", exc_info=True)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1465, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.10/logging/handlers.py\", line 75, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1218, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1100, in emit\n",
            "    msg = self.format(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 943, in format\n",
            "    return fmt.format(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 112, in format\n",
            "    formatted = super().format(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 686, in format\n",
            "    record.exc_text = self.formatException(record.exc_info)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 636, in formatException\n",
            "    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 119, in print_exception\n",
            "    te = TracebackException(type(value), value, tb, limit=limit, compact=True)\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 502, in __init__\n",
            "    self.stack = StackSummary.extract(\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 383, in extract\n",
            "    f.line\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 306, in line\n",
            "    self._line = linecache.getline(self.filename, self.lineno)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 30, in getline\n",
            "    lines = getlines(filename, module_globals)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 46, in getlines\n",
            "    return updatecache(filename, module_globals)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 136, in updatecache\n",
            "    with tokenize.open(fullname) as fp:\n",
            "  File \"/usr/lib/python3.10/tokenize.py\", line 396, in open\n",
            "    encoding, lines = detect_encoding(buffer.readline)\n",
            "  File \"/usr/lib/python3.10/tokenize.py\", line 365, in detect_encoding\n",
            "    first = read_or_stop()\n",
            "  File \"/usr/lib/python3.10/tokenize.py\", line 323, in read_or_stop\n",
            "    return readline()\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "/bin/bash: playwright: command not found\n"
          ]
        }
      ],
      "source": [
        "!pip install playwright\n",
        "!playwright install"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# łączenie się ze stroną internetową Hebe dla kategorii 'szampony'\n",
        "from bs4 import BeautifulSoup\n",
        "from playwright.async_api import async_playwright\n",
        "\n",
        "urls = set()\n",
        "\n",
        "async def run():\n",
        "    previous_length = len(urls)\n",
        "    async with async_playwright() as p:\n",
        "        browser = await p.chromium.launch()\n",
        "        page = await browser.new_page()\n",
        "        await page.goto(\"https://www.hebe.pl/pielegnacja-szampony/\")\n",
        "        while True:\n",
        "          await page.click('text=ZOBACZ WIĘCEJ')\n",
        "          # Pobieranie zawartości strony\n",
        "          content = await page.content()\n",
        "          # Scrapowanie przy użyciu parsera BeautifulSoup\n",
        "          soup = BeautifulSoup(content, 'html.parser')\n",
        "          # Wyszukiwanie kodów, zawierających fragment stron internetowych poszczególnych produktów\n",
        "          elements = soup.find_all(\"div\", class_=\"thumb-link\")\n",
        "          urls.update([link['data-href'] for link in elements])\n",
        "          print(len(urls))\n",
        "          if len(urls) != previous_length:\n",
        "            previous_length = len(urls)\n",
        "          else:\n",
        "            break\n",
        "        await browser.close()  \n",
        "\n",
        "await run()        "
      ],
      "metadata": {
        "id": "19as3CGLhAMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# utworzenie listy z adresami do poszczególnych produktów\n",
        "root = 'https://www.hebe.pl'\n",
        "web_pages = []\n",
        "for url in urls:\n",
        "  web_page = root + url\n",
        "  web_pages.append(web_page)     "
      ],
      "metadata": {
        "id": "uHWz-uQAtbwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(web_pages)"
      ],
      "metadata": {
        "id": "F8kOCAugthAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "7cyff0YPt_9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pobieranie danych o nazwach produktów\n",
        "names=[]\n",
        "\n",
        "for item in web_pages:\n",
        "  page = requests.get(item)\n",
        "  soup = BeautifulSoup(page.content, \"html.parser\")\n",
        "  name = soup.findAll('div', attrs={'class':'product-summary__title'})\n",
        "  names.append(name[-1].text)"
      ],
      "metadata": {
        "id": "AYVtOFPTt40-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pobieranie danych o składnikach produktów\n",
        "ingredients=[]\n",
        "\n",
        "for item in web_pages:\n",
        "  page = requests.get(item)\n",
        "  soup = BeautifulSoup(page.content, \"html.parser\")\n",
        "  data = soup.findAll('div', attrs={'class':'ui-expandable__inner'})\n",
        "  ingredients.append(data[-1].text)"
      ],
      "metadata": {
        "id": "WDg_p3j_zam4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pobieranie danych o markach produktów\n",
        "brand_names=[]\n",
        "\n",
        "for item in web_pages:\n",
        "  page = requests.get(item)\n",
        "  soup = BeautifulSoup(page.content, \"html.parser\")\n",
        "  brand = soup.findAll('a', attrs={'class':'product-content__link'})\n",
        "  if len(brand):\n",
        "    brand_names.append(brand[0].text)\n",
        "  else:\n",
        "    brand_names.append('brak')"
      ],
      "metadata": {
        "id": "jYdM-B3i4WrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pobieranie danych o ocenach produktów\n",
        "rates=[]\n",
        "\n",
        "for item in web_pages:\n",
        "  page = requests.get(item)\n",
        "  soup = BeautifulSoup(page.content, \"html.parser\")\n",
        "  rate = soup.findAll(\"div\", class_=\"reviews-stars__number reviews-stars__number--first\")\n",
        "  if len(rate):\n",
        "    rates.append(rate[0].text)\n",
        "  else:\n",
        "    rates.append('brak oceny')"
      ],
      "metadata": {
        "id": "5T39M6Ml9X7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pobieranie danych o cenach produktów\n",
        "prices=[]\n",
        "\n",
        "for item in web_pages:\n",
        "  page = requests.get(item)\n",
        "  soup = BeautifulSoup(page.content, \"html.parser\")\n",
        "  price = soup.findAll('span', attrs={'class':'price-product__amount'})\n",
        "  prices.append(price[-1].text)\n",
        "\n",
        "prices_decimal=[]\n",
        "\n",
        "for item in web_pages:\n",
        "  page = requests.get(item)\n",
        "  soup = BeautifulSoup(page.content, \"html.parser\")\n",
        "  decimal = soup.findAll('span', attrs={'class':'price-product__currency'})\n",
        "  prices_decimal.append(decimal[-1].text)"
      ],
      "metadata": {
        "id": "6PXy-Z7kso41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pobieranie danych o ilościach opinii\n",
        "reviews=[]\n",
        "for item in web_pages:\n",
        "  page = requests.get(item)\n",
        "  soup = BeautifulSoup(page.content, \"html.parser\")\n",
        "  review = soup.findAll(\"div\", class_=\"reviews-stars__count link link--underline link--bold link--hover\")\n",
        "  if len(review):\n",
        "    reviews.append(review[0].text)\n",
        "  else:\n",
        "    reviews.append('brak')"
      ],
      "metadata": {
        "id": "NBVQZhvZG657"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "4y2du6FUSQ4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stworzenie DataFrame z pobranych danych\n",
        "df = pd.DataFrame({'ProductName': names, 'Ingredients': ingredients, 'Rate': rates, 'Price': prices, 'Price_decimal': prices_decimal, 'Review': reviews, 'BrandName': brand_names})"
      ],
      "metadata": {
        "id": "88HL8dG6hInm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pobranie DataFrame jako plik csv\n",
        "df.to_csv('products.csv', index=False, encoding='utf-8')"
      ],
      "metadata": {
        "id": "zYSAXskMU_Zf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}